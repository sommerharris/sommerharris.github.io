---
layout: post
title: Week 4
---

**Reflections from the Cascad.ai conference**

This week a big highlight was watching the sessions from the Cascad.AI conference. The conference was designed to speak openly and share insights on emerging best practices for AI applications. With the goal of building and employing AI responsibly, this conference had speakers sharing insights from both industry and academia. 

This conference is relevant to our research project because our dataset is about cases of irresponsible AI. Learning more about best practices in responsible AI-- and hearing from analysts in industry and academia-- helps me understand what parts of the data might be most important to an analyst, and how to design a data visualization tool that can support the display of key insights.

Out of what was shared, the following take aways stood out to me the most. I also share how these insights might impact the design of a visualization tool:

-the importance of people having a seat at the table for the human rights conversations related to AI without needing to understand the technical context of how AI works, the need for technological review boards (similar to transportation or medical review boards)

-acknowledging that we are all technological citizens and that technology does not happen in a vacuum.

-how important it is for human actors to be responsible for the AI they create rather than falsely attributing the capacity for moral/ethical reasoning to AI

-the importance of ultimately giving the doman expert flexibility and power on how the information they are analyzing is displayed
